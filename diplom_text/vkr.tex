\documentclass[a4paper,12pt]{extarticle}
\usepackage{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{indentfirst}
\usepackage[
backend=bibtex,
style=numeric,
maxbibnames=99
]{biblatex}
\addbibresource{refs.bib}
\usepackage[colorlinks,citecolor=blue,linkcolor=blue,bookmarks=false,hypertexnames=true, urlcolor=blue]{hyperref} 
\usepackage{indentfirst}
\usepackage{mathtools}
\usepackage{booktabs}
\usepackage[flushleft]{threeparttable}
\usepackage{tablefootnote}

\usepackage{chngcntr} % нумерация графиков и таблиц по секциям
\counterwithin{table}{section}
\counterwithin{figure}{section}

\graphicspath{{graphics/}}%путь к рисункам

\makeatletter
% \renewcommand{\@biblabel}[1]{#1.} % Заменяем библиографию с квадратных скобок на точку:
\makeatother

\geometry{left=2.5cm}% левое поле
\geometry{right=1.0cm}% правое поле
\geometry{top=2.0cm}% верхнее поле
\geometry{bottom=2.0cm}% нижнее поле
\setlength{\parindent}{1.25cm}
\renewcommand{\baselinestretch}{1.5} % междустрочный интервал


\newcommand{\bibref}[3]{\hyperlink{#1}{#2 (#3)}} % biblabel, authors, year
\addto\captionsrussian{\def\refname{Список литературы (или источников)}} 

\renewcommand{\theenumi}{\arabic{enumi}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\labelenumi}{\arabic{enumi}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\theenumii}{.\arabic{enumii}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}.}% Меняем везде перечисления на цифра.цифра
\renewcommand{\theenumiii}{.\arabic{enumiii}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\labelenumiii}{\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}.}% Меняем везде перечисления на цифра.цифра

\begin{document}
\input{title_vkr}% это титульный лист - выберите подходящий вам из имеющихся в проекте вариантов (kr - курсовая работа у 3 курса, vkr - выпускная квалификационная работа у 4 курса)
\newpage
\setcounter{page}{2}

{
	\hypersetup{linkcolor=black}
	\tableofcontents
}

\newpage

\newpage
\section*{Аннотация}   % this is how to use russian
Выпускная квалификационная работа посвящена разработке эффективного и простого в использовании приложения, которое позволит пользователям легко и быстро подбирать категорию товара для маркетплейса по его фотографии, а также составлять к нему SEO-описание. В работе проведен анализ существующих решений, рассмотрены различные архитектуры нейронных сетей, описаны задачи классификации и создания подписей к изображениям, разработаны решения для реализации моделей нейронной сети для SEO-оптимизации карточки товара, учитывающие специфику данных. Особое внимание уделено использованным метрикам и методам сбора данных. Результатом работы является разработанный сервис, в основе которого реализована нейронная сеть, способная классифицировать товары на маркетплейсе на основе их фотографий и генерировать соответствующие к ним описания. Дальнейшие исследования в этой области могут включать улучшения качества результатов, а также расширение функциональности за счет генерации описания с помощью ключевых слов.

\addcontentsline{toc}{section}{Аннотация}

\newpage
\section*{Abstract}   % this is how to use russian
The final qualification work is devoted to the development of an effective and easy-to-use application that will allow users to easily and quickly select a product category for a marketplace based on its photo, as well as create an SEO description for it. The paper analyzes existing solutions, examines various architectures of neural networks, describes the tasks of classifying and creating captions to images, and develops solutions for implementing neural network models for SEO optimization of product cards, taking into account the specifics of the data. Special attention is paid to the metrics and data collection methods used. The result of the work is a developed service based on a neural network capable of classifying products on the marketplace based on their photos and generating descriptions corresponding to them. Further research in this area may include improvements in the quality of results, as well as expanding functionality by generating a description using keywords.

\newpage
\section*{Ключевые слова}   % this is how to use russian

\textbf{Маркетплейс (от англ. marketplace; электронная торговая площадка)} — платформа электронной коммерции, интернет-магазин электронной торговли, предоставляющий информацию о продукте или услуге третьих лиц.

\textbf{SEO-оптимизация карточек товара} — это процесс улучшения информации о товаре на маркетплейсе, чтобы она была более привлекательной и доступной для поисковых систем и пользователей. Цель состоит в том, чтобы повысить видимость товара в результатах поиска, привлечь больше потенциальных покупателей и увеличить конверсию.

\textbf{Искусственный интеллект (ИИ) (от англ. Artificial Intelligence, AI)} — свойство интеллектуальных компьютерных систем, обладающих возможностями выполнять творческие задачи, которые считаются прерогативой человека \cite{ai}.

\textbf{Машинное обучение (от англ. Machine Learning, ML)} — область искусственного интеллекта, изучающий различные способы построения обучающихся алгоритмов. Среди множества парадигм и подходов в машинном обучении выделяются нейронные сети \cite{ml}. 

\textbf{Компьютерное зрение (от англ. Computer Vision, CV)} — область искусственного интеллекта, которое занимается задачами, связанными с анализом изображений и видео \cite{cv}.

\textbf{Обработка естественного языка (от англ. Natural Language Processing, NLP)} — это направление в машинном обучении, посвящённое распознаванию, генерации и обработке устной и письменной человеческой речи \cite{nlp}.

\textbf{Нейронная сеть (от англ. Neural Network)} — математическая модель, а также ее программное или аппаратное воплощение, построенная по принципу организации и функционирования биологических нейронных сетей, используемая для решения задач ИИ \cite{neural}.

Сокращения названий архитектур нейронных сетей:
\begin{itemize}
	\item сверточная нейронная сеть (от англ. Convolutional Neural Network, CNN);
	\item рекуррентная нейронная сеть (от англ. Recurrent Neural Network, RNN);
	\item рекуррентная нейронная сеть с долгой краткосрочной памятью (от англ. Long Short-Term Memory, LSTM);
	\item управляемый рекуррентный блок (от англ. Gated Recurrent Unit, GRU);
	\item генеративный предварительно обученный трансформер, (от англ. Generative Pre-trained Transformer, GPT).
\end{itemize}

\newpage
\section*{Введение}   % this is how to use russian
В современном мире маркетплейсы стали неотъемлемой частью электронной коммерции, предоставляя платформы для продажи товаров и услуг различным производителям и ритейлерам.
В 2023 году маркетплейсы продолжили быть главной движущей силой российской онлайн-торговли. Рост объема трат на маркетплейсах в 1,5 раза по сравнению с предыдущим годом свидетельствует о том, что интерес потребителей к онлайн-покупкам только укрепляется. На это влияют общерыночные факторы: продолжают развиваться альтернативные каналы поставок продукции ушедших брендов, улучшаются условия доставки, повышается удобство пользования платформами, расширяется сеть пунктов выдачи.

Согласно исследованиям «Tinkoff Ecommerce»\cite{tinkoff-research}, количество транзакций на маркетплейсах за год выросло на 63\% (см. рисунок ~\ref{fig:marketplaces-purchases-increased}). Лидерами по росту количества покупок стали «Мегамаркет» (число транзакций выросло в 4,3 раза), «Wildberries» (в 2 раза) и «Ozon» (в 1,6 раза).

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.3]{marketplaces-purchases-increased.png}
	\caption{Динамика покупок на маркетплейсах в регионах \cite{tinkoff-research}.}
	\label{fig:marketplaces-purchases-increased}
\end{figure} 

Появился тренд на рост популярности маркетплейсов в российских регионах. В 2023 году жители российских городов стали значительно активнее совершать покупки на маркетплейсах: выросло как количество транзакций на онлайн-площадках, так и их сумма (см. рисунок ~\ref{fig:marketplaces-regions}). По количеству совершенных транзакций особенно заметен рост в таких городах, как Омск (+91\%), Красноярск (+88\%), Новосибирск (+79\%), Челябинск (+79\%) и Волгоград (+75\%). В Москве зафиксирован наименьший прирост числа транзакций (+41\%). Увеличение интереса жителей регионов к маркетплейсам объясняется рядом причин: расширением географии присутствия площадок, развитием сетей пунктов выдачей заказов и логистических сервисов, улучшением условий доставки.

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.3]{marketplaces-regions.png}
	\caption{Динамика покупок на маркетплейсах в регионах \cite{tinkoff-research}.}
	\label{fig:marketplaces-regions}
\end{figure}  

Вместе с тем выросло количество селлеров на 8\%. Рынок становится более зрелым: место неопытных продавцов занимают более профессиональные. Они ведут бизнес более уверенно, укрепляют свои позиции на площадках и торгуют на нескольких платформах одновременно. Количество селлеров, ведущих торговлю на двух и более маркетплейсах, за год увеличилось на 17\%. Самой привлекательной платформой для старта бизнеса является «Wildberries»: 63\% продавцов в конце 2023 года выбирали ее в качестве первой площадки (см. рисунок ~\ref{fig:marketplaces-top}).

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.3]{marketplaces-top.png}
	\caption{Популярность маркетплейсов за 2023 год \cite{tinkoff-research}.}
	\label{fig:marketplaces-top}
\end{figure} 

С увеличением конкуренции продавцы все чаще обращаются к системам, которые могут помочь им в продажах, а также автоматизировать процесс работы. Одним из ключевых факторов успешной продажи становится эффективная SEO-оптимизация карточек товаров. Подбор наиболее подходящей категории и создание продаваемого описания, содержащего ключевые слова, позволяет улучшить видимость товаров в результатах поиска как на самом маркетплейсе, так и в поисковых системах, что напрямую влияет на увеличение продаж.

На данный момент существуют несколько сервисов (например, TurboTextPro, Gerwin, CopyMonkey, подробнее можно ознакомиться в пункте \ref{exists}), позволяющих сгенерировать описание товаров по характеристикам, ключевым словам или фотографии. Однако, качество сгенерированных описаний не всегда позволяют использовать их в системах автономного управления. В настоящее время российский рынок не предлагает специальных технологий и решений для подбора наиболее подходящей категории товара на маркетплейсе. Таким образом, задача создания качественного инструмента для эффективной SEO-оптимизации карточек товаров является актуальной. 

\addcontentsline{toc}{section}{Введение}

\newpage
\section{Цель и задачи работы}

Цель данной работы — разработать сервис, в основе которого будет реализована модель нейронной сети, способная классифицировать товары на маркетплейсе на основе их фотографий и генерировать соответствующие к ним описания.

Для достижения поставленной цели необходимо решить следующие задачи:
\begin{itemize}
	\item подготовить набор данных, содержащий изображения товаров и соответствующие им категории и текстовые описания;
	\item провести исследование текущих архитектур нейронных сетей, используемых для классификации изображений и генерации текста, и на основе этого исследования выбрать наиболее подходящую архитектуру или их комбинацию для решения поставленной задачи;
	\item обучить выбранную нейронную сеть на подготовленных данных, оптимизировать и настроить параметры модели для повышения её производительности и качества результатов, а затем оценить эффективность реализованной архитектуры нейронной сети;
	\item интегрировать модель в программное обеспечение.
\end{itemize}

\newpage
\section{Постановка задачи}

В соответствии с заданием на выпускную квалификационную работу необходимо разработать программное обеспечение, на вход которого подаются фотографии товара. Выходом являются наиболее подходящая категория товара для маркетплейса и его SEO-описание.

Допущения:
\begin{itemize}
	\item рассматривается только маркетплейс «Wildberries»;
	\item глубина подбора категории — второй уровень вложенности.
\end{itemize}

Постановка задачи в виде IDEF0-диаграммы представлена на рисунке \ref{fig:hse-idef0}. 

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.8]{hseidef0.png}
	\caption{Постановка задачи.}
	\label{fig:hse-idef0}
\end{figure}

Для достижения целей и задач проекта требуется решить задачу многоклассовой классификации изображений (от англ. multiclass image classification) для подбора наиболее подходящей категории по фотографии товара, а также решить задачу создания подписей к изображениям (от англ. image captioning). Для успешной реализации проекта необходимо выбрать подходящие модели и определить метрики, которые будут использоваться для оценки их эффективности.

\newpage
\section{Обзор существующих решений}\label{exists}

На данный момент существуют несколько сервисов, позволяющих сгенерировать описание товаров по характеристикам, ключевым словам или фотографии. Однако нет сервисов для подбора наиболее подходящей категории товара на маркетплейсе по фотографии. Для продавцов было бы крайне полезно иметь эти функциональности одновременно. Это значительно упростило бы процесс подготовки и публикации товаров, а также повысило эффективность и точность их работы.

\subsection{TurboText.Pro}

TurboText.Pro — создает описания по фотографии или характеристикам товара \cite{turbotextpro}. Во втором случае текст будет более высокого качества, так как ИИ напишет описание по заданным параметрам. Нейросеть создает три описания для одного товара. Можно выбрать самый лучший вариант и разместить его в товарной карточке, или использовать все на разных площадках. А еще можно заказать улучшение текста или SEO-оптимизацию для вывода товара в топ на «Wildberries» у опытных копирайтеров.

Плюсы данного сервисы:
\begin{itemize}
	\item высокая скорость генерации (1-2 секунды);
	\item развернутое описание товара;
	\item все функции доступны бесплатно;
	\item можно сгенерировать описание товара по фотографии или характеристикам;
	\item есть возможность заказать SEO-оптимизацию описания товара.
\end{itemize}

Минусы:
\begin{itemize}
	\item генерация только на русском языке;
	\item качество описания по фото ниже, чем описания по характеристикам товара;
	\item есть ограничение при генерации описания по характеристикам — от 30 символов.
\end{itemize}

На рисунке \ref{fig:turbotextpro} представлен интерфейс данного сервиса.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.4]{turbotextpro.png}
	\caption{Сервис TurboText.Pro.}
	\label{fig:turbotextpro}
\end{figure}

\newpage
\subsection{Gerwin}

Gerwin — создает описания для товара по ключевым словам \cite{gerwin}.

Плюсы данного сервисы:
\begin{itemize}
	\item высокая скорость генерации (1-2 секунды);
	\item есть варианты генерации на разных языках;
	\item разные описания к одному товару на выбор;
	\item можно протестировать сервис бесплатно по промокоду.
\end{itemize}

Минусы:
\begin{itemize}
	\item ограничение по количеству ключевых слов — не больше 3-х;
	\item из-за ограничений исходных данных нельзя сделать более развернутое описание товара;
	\item нет возможности сгенерировать описание товара по фотографии;
	\item чтобы протестировать сервис бесплатно, нужно «добыть» промокод через Telegram-бота. Время ожидания — в течение 8 часов.
\end{itemize}

На рисунке \ref{fig:gerwin} представлен интерфейс данного сервиса.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.15]{gerwin.png}
	\caption{Сервис Gerwin.}
	\label{fig:gerwin}
\end{figure}

\newpage
\subsection{CopyMonkey}

CopyMonkey — создает описания для товара по его характеристикам и ключевым словам \cite{copymonkey}.

Плюсы данного сервисы:
\begin{itemize}
	\item высокая скорость генерации (1-2 секунды);
	\item есть бесплатные попытки ежедневно;
	\item разные описания к одному товару на выбор;
	\item можно протестировать сервис бесплатно по промокоду.
\end{itemize}

Минусы:
\begin{itemize}
	\item низкое качество текста, нейросеть просто сгруппировала характеристики;
	\item есть логические несостыковки в тексте;
	\item один вариант описания товара без возможности выбора.
\end{itemize}

На рисунке \ref{fig:copymonkey} представлен интерфейс данного сервиса.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.35]{copymonkey.png}
	\caption{Сервис CopyMonkey.}
	\label{fig:copymonkey}
\end{figure}

\newpage
\subsection{Сравнительный анализ существующих решений}

TurboText.Pro генерирует более развернутое описание товара, но есть пара неточностей, которые легко поправить, потратив на это не больше минуты. После описание можно размещать в карточке товара интернет-магазина или на маркетплейсе. CopyMonkey и Gerwin справляются со своей задачей хуже. Все три сервиса можно протестировать бесплатно и выбрать тот, который подходит для работы лучше всего.

Сравнительный анализ существующих решений может быть представлен в таблице \ref{compare_exist}.

\begin{table}[h]
	\centering
	\begin{tabular}{ | l | l | l | l | }
		\hline
		Сервис & Стоимость & Генерация & Качество \\
		& & по фотографии & генерации \\ \hline
		TurboText.Pro & Бесплатно & + & Высокое  \\ \hline
		Gerwin & Бесплатно & — & Среднее \\ \hline
		Copymonkey & Бесплатно & — & Низкое \\
		& 3 попытки в день &  &  \\ \hline
	\end{tabular}
	\caption{Cравнение существующих решений по генерации SEO-описания товара.}
	\label{compare_exist}
\end{table}


\newpage
\section{Данные} 

Для того чтобы датасет был полезным и эффективным для достижения поставленной цели и задач проекта, он должен удовлетворять следующим требованиям:
\begin{itemize}
	\item данные должны быть достоверными и правильно отражать характеристики товаров;
	\item данные должны иметь четкую классификацию товаров по категориям и подкатегориям, соответствующих структуре категорий маркетплейсов в РФ (например, «Ozon» или «Wildberries»);
	\item данные должны быть структурированы в удобном для обработки формате, таком как CSV, JSON или в виде базы данных;
	\item данные должны включать фотографии товаров с разных ракурсов и в различных вариациях, а также иметь их текстовые описания;
	\item необходимо иметь достаточное количество данных для каждой категории товаров, чтобы обеспечить репрезентативность для анализа и обучения моделей;
	\item данные должны быть актуальными и регулярно обновляемыми для отражения текущих трендов и состояния рынка.
\end{itemize}

На данный момент существуют несколько датасетов для работы с товарами, взятых с интернет-магазинов электронной торговли:
\begin{itemize}
	\item Fashion-MNIST — подходит для продуктовой категоризации. MNIST содержит почти 60 000 обучающих изображений и 10 000 тестовых изображений одежды и аксессуаров, разделенные на 10 категорий (Футболка, Брюки, Свитер, Платье, Пальто, Сандалии, Рубашка, Кроссовки, Сумка, Ботинки). Каждое изображение имеет размер 28x28 пикселей и представлено в оттенках серого. \cite{fashion_mnist}.
	\item Innerwear Data from Victoria's Secret and Others — содержит данные с 600 000+ товаров нижнего белья, извлеченного из популярных торговых объектов. Включает в себя описание продукта, цену, категорию и рейтинг \cite{victoria_secret_data}.
	\item eCommerce Item Data — набор данных, который содержит артикулы и связанные с ними описания продуктов из каталога продукции бренда верхней одежды. Подходит для рекомендательных систем \cite{eсommerce_item_data}.
	\item Fashion Products on Amazon — набор данных, созданный путем извлечения данных из Amazon. Он состоит примерно из 22 000 товаров на Amazon и включает в себя описание продукта, цену, категорию и рейтинг \cite{amazon_data}.
\end{itemize}

Данные для поставленной задачи собирались самостоятельно, поскольку в открытых источниках не имеется удовлетворяющего всем требованиям датасета. Был проведен анализ на возможность парсинга наиболее популярных маркетплейсов в РФ «Ozon» и «Wildberries».

Анализ парсинга «Ozon»:
\begin{itemize}
\item Сильная защита, частая блокировка пользователей, смена userAgent не всегда помогает.
\item На странице много динамического контента и ленивой подгрузки, что создает трудности при парсинге динамически подгружаемых категорий.
\item Огромное количество подкатегорий товара.
\item Большая вариативность описания, нет единного шаблона для парсинга. Так например, когда-то вместо текстов могут быть просто картинки или описание товара сопряженно с картинкой.
\item Динамическая подгрузка отзывов, которая усложняет скачивание фотографий из них.
\end{itemize}

Анализ парсинга «Wildberries»:
\begin{itemize}
	\item Слабая защита, не требуется смена userAgent.
	\item Cтатический контент для парсинга категорий и подкатегорий.
	\item При парсинге товаров существует их ленивая подгрузка: для одной подкатегорий подгружается 15 товаров, чтобы подгрузить следующие нужно «прокрутить» экран вниз.
	\item Единное оформление карточки товара, упрощает парсинг товара: его описание, характеристики, фотографии из сео и из отзывов.
\end{itemize}

Принято решения писать ВКР для продавцов, использующий «Wildberries», так как им чаще всего пользуются и он легче подается парсингу. Данные собирались согласно особенностям структуры этого маркетплейса. Для удобства введем некоторые термины, которыми будем оперировать далее:
\begin{itemize}
	\item \textbf{Карточка товара} – это страница продукта на маркетплейсе, где размещена информация о товаре, фотографии, описание цены и кнопка «Купить»
	\item \textbf{Конечная категория} – это категория, на которых располагаются карточки товаров
	\item \textbf{Материнская категория} – это категория, которая содержит конечные и материнские категории и на которой не располагаются карточки товаров
\end{itemize}

Каталог «Wildberries» разделен на категории, в которых размещены карточки товаров одного типа. Категории выстроены по принципу дерева. Есть основные «широкие» категории, такие как «Женщинам», «Дом», «Продукты», которые объединяют внутри себя более мелкие подкатегории. Например, в разделе «Дом» имеются подкатегории «Ванная», «Кухня», «Спальня» и тд, которые в свою очередь могут подразделяться на еще более маленькие подкатегории. 

Требуемые данные располагались на товарных карточках, в которые можно попасть только зная конечную категорию товара. Поэтому было принято решение разделить сбор данных на 2 этапа. На первом этапе был произведен сбор всех имеющихся на «Wildberries» конечных категорий. На втором – сбор необходимой информации с карточек товаров.

\subsection{Этап 1}

«Wildberries» предлагает 22 основные категории (см. рисунок~\ref{fig:wildberries1}), из которых одна является конечной категорией. Данные категории в дальнейшем будем называть категориями первой вложенности. Их подкатегории, соответственно, будут называться категориями второй вложенности. И так далее, спускаясь все ниже по дереву категорий. Экспериментальным путем была выявлена максимальная глубина вложенности – 5.

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{wildberries1.png}
	\caption{Структура каталога «Wildberries» на примере категории «Обувь».}
	\label{fig:wildberries1}
\end{figure} 

Для правильного формирования таргета для классификации при сохранении ссылки на конечную категория нужно было учитывать весь путь по дереву категорий, начиная с первой вложенности. Решением данной задачи стало создание таблицы, где отражалось какие категории было предшествовавшими конкретной конечной категории (см. таблицу~\ref{table:datastatistic0}). При отсутствии более глубокой вложенности на месте данных категорий ставились «NaN». Таким образом, было собрано 1668 конечных категорий.

\begin{table}[ht]
\caption{Фрагмент таблицы, полученной после первого этапа сбора данных.}
\label{table:datastatistic0}
\footnotesize
\centering
	\begin{tabular}{lrrrrrr}
		\toprule
		{} & \multicolumn{1}{c}{$\mathsf{category_1}$} &\multicolumn{1}{c}{$\mathsf{category_2}$} &  \multicolumn{1}{c}{$\mathsf{category_3}$} & \multicolumn{1}{c}{$\mathsf{category_4}$} &  \multicolumn{1}{c}{$\mathsf{category_5}$} & \multicolumn{1}{c}{$\mathsf{url}$}\\
		\midrule
		437 & Дом & Предметы интерьера & Фоторамки и фотоальбомы & Фотоальбомы       & NaN              & https://www.wildberries.ru/catalog/dlya-doma/predmety-interera/fotoramki-i-fotoalbomy/fotoalbomy\\
		438 & Дом & Предметы интерьера & Картины и постеры       & Рамы для постеров & NaN              & https://www.wildberries.ru/catalog/dlya-doma/predmety-interera/kartiny/ramy-dlya-posterov\\
		439 & Дом & Предметы интерьера & Картины и постеры       & Постеры           & Детская тематика & https://www.wildberries.ru/catalog/dlya-doma/predmety-interera/kartiny/postery/detskaya-tematika\\
		440 & Дом & Предметы интерьера & Картины и постеры       & Картины           & Арт и абстракция & https://www.wildberries.ru/catalog/dlya-doma/predmety-interera/kartiny/kartiny/art-i-abstraktsiya\\
		441 & Дом & Предметы интерьера & Картины и постеры       & Постеры           & Фэнтези          & https://www.wildberries.ru/catalog/dlya-doma/predmety-interera/kartiny/postery/fentezi\\
		\bottomrule
	\end{tabular}
\end{table}

Составление данной таблицы производилось посредством парсинга данных с сайта «Wildberries» через Python с использованием библиотек selenium и BeautifulSoup. Блокировок со стороны маркетплейса замечено не было. Особенность и неудобством парсинга была динамическая подгрузка страниц, которая вынуждала выдерживать паузы в несколько секунд для удовлетворяющей прогрузке страницы. Данное обстоятельство привело с значительному увеличению времени парсинга данных.

При анализе собранной таблицы были выявлены некоторые особенности категориальной политики «Wildberries». Во-первых, категории у данного маркетплейса не фиксированы. Например, было отмечено, что часть категорий активно перемещается из раздела в раздел, какие-то категории могут пропадать, также могут появляться новые категории. Данные, собранные в текущем датасете, актуальны на конец января 2024 года. Однако для поддержания списка категорий в актуальном состоянии необходимы механизмы регулярного обновления данных. Во-вторых, на маркетплейсе имеются конечные категории, ссылающиеся на одни и те же url страницы. Подобные категории будут называться дублирующими. Подобные дубляжи могли иметь разное происхождение: особенности маркетинга и неудачное время парсинга, выпавшее на перемещение категорий. С точки зрения маркетинга подобные дублирования оправданы, поскольку потенциальный покупатели могут по своим соображениям относить одни и те же товары к разным категориям. Для примера, категория «Коврики» находилась в разделе «Автотовары\_Коврики» и «Электроника\_Автоэлектроника\&и\&навигация\_Коврики». Для корректной работы модели была написана отдельная процедура удаления подобных дублирующих категорий. Выбор, какой из дубликатов оставлять, производился вручную. Всего было найдено 69 дублирующих ссылок, которые могли встречаться 2 и более раза. Таким образом, после удаления в таблице осталось 1580 категорий.

Далее можно было переходить ко 2му этапу.


\subsection{Этап 2}

Второй этап сбора данных заключался в прохождении по собранному ранее списку конечных категорий и сбора из каждой из них информации с карточек товаров. Было принято решение брать по 20 товаров из каждой конечной категории. Из каждой карточки товара сохранялось первое фотография от продавца, первая фотография из отзыва и описание товара (см. рисунок~\ref{fig:wildberries2}). Первая фотография от продавца бралась по причине ее обязательного присутствия в карточке товара, а также гарантированного качественного изображения товара на ней. Однако поскольку разрабатываемый сервис рассчитан на работу в большинстве случаев с фотографиями от пользователей, все дефекты, присущие любительским фотографиям могут иметь место быть. Поэтому для стабильности предсказаний классификационной модели, было решено подавать в нее также фотографии из отзывов, которые максимально близко будут похожи на фотографии, с которыми будет работать в дальнейшем сервис. Описания товара были нужны для задачи генерации текстовых описаний к изображениям. В итоге при полном наборе для каждой конечной категории имелось 40 фотографий (20 фотографий от продавцов и 20 фотографий из отзывов) и 20 описаний.

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{wildberries2.png}
	\caption{Пример карточки товара на «Wildberries». Верхний левый прямоугольник – первая фотография от продавца. Нижний левый прямоугольник – первая фотография из отзыва. Правый прямоугольник – текстовое описания товара.}
	\label{fig:wildberries2}
\end{figure}

При выполнении данного этапа было несколько трудностей. Во-первых, стандартная на «Wildberries» динамическая прогрузка страниц, увеличивающая время парсинга более чем в 3 раза. Приходилось делать паузы при открытии страницы с карточкой товара, при открытии описания, лежащее в отдельной вкладке, и пролистывание страницы вниз для подгрузки информации об отзывах. Примерное время парсинга данных, затраченное на второй этап, равнялось 2м неделям. Во-вторых, имели товары с меткой «18+», для которых требовалось дополнительное нажатие кнопки, подтверждающее достижение указанного возраста. В-третьих, некоторые поля в карточке товара заключали в себе картинки, которые вынуждали в определенных случаях дополнительно пролистывать страницу вниз. В-четвертых, для нажатия кнопки с целью получения описание к товару, выдвигалось требование расположение кнопки в зоне видимости экрана. Это приводило к еще более тонкой настройке пролистывания страницы, подобранной под конкретный размер экрана компьютера.

Для сохранения данных из карточек товара была придумала специальная структура с целью дальнейшего удобства использовании в задаче классификации и генерации текста. Все товары, собранные из одной конечной категории, сохранялись в отдельную папку, содержащую следующие элементы:
\begin{itemize}
	\item папку «card», куда складывались фотографии от продавцов
	\item папку «feedbacks», куда складывались фотографии из отзывов
	\item файл «descriptions.csv», где сохранялись описания к товарам
\end{itemize}

Название данной папки определялось посредство таблицы 1 и складывалось из всех материнских категорий, участвовавших в пути к конечной категории. Например, для конечной категории «Фотоальбомы» (см. таблицу~\ref{table:datastatistic0}) название папки было следующее: «Дом\_Предметы\&интерьера\_Фоторамки\&и\&фотоальбомы\_Фотоальбомы», а для категории «Фэнтези» - «Дом\_Предметы\&интерьера\_Картины\&и\&постеры\_Постеры\_Фэнтези». Более подробно об использовании подобной структуры ранения данных будет описание в главе \_\_\_ в разделе \_\_\_.

Первичный анализ собранных данных выявил, что не у всех товаров имелись отзывы с фотографиями и описания. Описания имелись в 99.8\% проценте случаев. В таблице~\ref{table:datastatistic1} приведены некоторые статистические данные о собранных фотография от продавца и из отзыва. Можно заметить, что некоторые конечные категории были полностью без фотографий в отзывах. Однако, опираясь на перцентили, можно сделать вывод, что таких категорий было довольно мало. Касательно фотографий от продавцов можно сделать 2 вывода. Во-первых, есть категории, представленные менее чем 20ю товарами. Во-вторых, есть как минимум одна категория, в которой имеется только 1 товар. Подобные категории нас не устраивают, потому что далее будет производиться деление каждой категории на 2 части, и категории с одним товаром невозможно будет разделить.

\begin{table}[ht]
	\caption{Описательная статистика по фотографиям от продавца (столбец «card») и фотографиям из отзыва (столбец «feedbacks»).}
	\label{table:datastatistic1}
	\footnotesize
	\centering
	\begin{tabular}{l|rr}
		\toprule
		{} & \multicolumn{1}{c}{$\mathsf{card}$} & \multicolumn{1}{c}{$\mathsf{feedbacks}$}\\
		\midrule
		count &	1580  & 1580\\
		mean  & 19.98 & 17.72\\
		std   & 0.63  &	4.23\\
		min   &	1     &	0\\
		25\%  &	20    &	18\\
		50\%  &	20    &	19\\
		75\%  &	20    &	20\\
		max   &	20    &	20\\
		\bottomrule
	\end{tabular}
\end{table}

Всего категорий, представленных менее 20 товарами, было выявлено 5 штук (см. таблицу~\ref{table:datastatistic2}). Из них представляли наибольший интерес \_ и \_, из-за чересчур малого количества товаров. Категорию с одним товаром было решено удалить. Таким образом, осталось 1579 конечных категорий, с которыми шла вся дальнейшая работа.

\begin{table}[ht]
	\caption{Таблица с категориями, имеющими менее 20 товаров.}
	\label{table:datastatistic2}
	\footnotesize
	\centering
	\begin{tabular}{rc}
		\toprule
		\multicolumn{1}{c}{кол-во товаров} & \multicolumn{1}{c}{категория}\\
		\midrule
		18 & Дом\_Кухня\_Кухонный\&текстиль\_Чехлы\&для\&ручек\&холодильников\\
		4  & Дом\_Освещение\_Лифты\&для\&люстр\\
		19 & Мебель\_Гардеробная\&мебель\_Ящики\\
		1  & Мебель\_Офисная\&мебель\_Перегородки\&офисные\\
		19 & Мебель\_Офисная\&мебель\_Шкафы\\
		\bottomrule
	\end{tabular}
\end{table}

При более детально рассмотрении собранных данных было замечено, что фотографии из отзывов довольно шумные (см. рисунок~\ref{fig:dataexample1}). Очень много одинаковых фотографий, фотографий, где не очень понятно, что изображено. Поэтому для дальнейшей работы использовались только фотографии товара от продавца.

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{dataexample1.png}
	\caption{Фотографии из отзывов в категории «Игрушки\_Антистресс».}
	\label{fig:dataexample1}
\end{figure}

Далее интересно было рассмотреть количество собранных данных в разрезе категорий первой вложенности (см. рисунок~\ref{fig:amount_of_categoty}). Из круговой диаграммы можно заметить, что категории довольно несбалансированный. Например, категория «Дом» вмещает в себя порядка 6000 пример. В то время как в категории «Ювелирные\&изделия» только 320 примеров.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.8]{amount_of_categoty.png}
	\caption{Распределение данных по категориям первой вложенности.}
	\label{fig:amount_of_categoty}
\end{figure}

Подобную картину можно наблюдать в категориях всех вложенностей (см. приложение~\ref{appendix:amount_of_categor2}).

После появление базового понимания данных надо было приступать к их детальному изучению. Как правило, парсинг большого количества данных, тем более с постоянно меняющихся маркетплейсов, не проходит идеально. В сохраненных данных могут быть оплошности, которые помешают грамотно решать задачу классификации и генерации текста. Приведем некоторые примеры, выявленных особенностей, требуемых принятие решений с нашей стороны:
\begin{itemize}
	\item Встречаются категории, которые с точки зрения категорийного менеджмента, имеют место быть. Одна для классификационной модели машинного обучения такие категории будут не осиливаемыми. Например, в разделе «Женщинам» есть подкатегории «Женщинам\_Белье» и «Женщинам\_Большие\&размеры\_Белье». Если детально изучить фотографии, которые в этих категориях присутствуют, можно сделать вывод, что особых различий между ними нет. Единственное, что было подмечено, что на очень немногих фотографиях стоит надпись «4XL» или что-то подобное, указывающее, что у данного товара имеются большие размера. Более того, в обеих категориях присутствуют одинаковые товары.
	\item В данных попадались «мусорные» категории. Предположительно, подобное возникало из-за изменения url ссылок на категории со стороны «Wildberries». В подобных категориях находились товары, собранные случайным образом из всевозможных категорий с маркетплейса.
	\item Распределение товаров по категориям не очень четкая задача. В связи с этим встречались одинаковые товары, находящиеся в разных категориях. Например, одна и та же продукт мог находиться в категориях «Зоотовары\_Груминг\&и\&уход», «Зоотовары\_Для\&кошек\_Груминг\&и\&уход» и «Зоотовары\_Для\&собак\_Груминг\&и\&уход».
	\item В части материнских категорий встречались разделы «Подарки» (например, материнские категории «Мужчинам\_Подарки\&мужчинам» и «Женщинам\_Подарки\&женщинам»), куда были собраны товары из совершенно разных категорий, таких как «Аксессуары», «Дом», «Продукты» и тд.
	\item Поскольку при парсинге из каждой категории брались первые 20 товаров, появляется неконтролируемый фактор того, какие товары стоят вначале. Как правило, пользователи смотрят только на первые товары в выдаче. Поэтому на маркетплейсах существуют множество механизмов и правил отбора товаров, которые будут показаны пользователю в начале. В нашем случае было замечено, что некоторые категории стали более шумными из-за сезонных товаров. Например, в категории «Зоотовары\_Фермерство» были найдены пасхальные яйца.
	\item Бывали категории, которые по смыслу имели место быть как отдельные категории, однако в них были собраны не совсем подходящие товары. Например, в категории «Мужчинам\_Религиозная\_Православие» находились обычные рубашки и штаны, часть из которых присутствовала также в категории «Мужчинам\_Рубашки» и «Мужчинам\_Брюки».
\end{itemize}

Приведенные особенности сохраненных данных требовали ручной очистки датасета. Необходимо было применять следующие действия: полное удаление категории, удаление конкретной фотографии из отзыва, удаление товара полностью (фотографию от продавца, из отзыва и описание к нему) и произведение полного переноса товара (фотографию от продавца, из отзыва и описание к нему) из одной категории в другую. Для удобства и быстроты данной процедуры были написаны функции, позволяющие механизмами Python вносить изменения в собранные данные.

По окончании данной процедуры было подмечено, что категории требовали очистки в разной степени. Какие-то категории, как «Зоотовары», требовали практически полного переформирования. Другие категории обходились легкой очисткой, например «Продукты». Некоторые категории совсем не требовала вмешательства. Таким образом, финальный датасет стал состоять из 1459 конечных категорий (см. таблицу~\ref{table:datastatistic2}).

\begin{table}[ht]
	\caption{Описательная статистика по фотографиям от продавца после очистки собранных данных. \textsl{Примечание:} статистика по фотографиям из отзывов не приведена, поскольку, как упоминалось ранее, решено было в дальнейшем работать только с фотографиями от продавца.}
	\label{table:datastatistic3}
	\footnotesize
	\centering
	\begin{tabular}{l|r}
		\toprule
		{} & \multicolumn{1}{c}{$\mathsf{card}$}\\
		\midrule
		count &	1459\\
		mean  & 20.09\\
		std   & 2.32\\
		min   &	4\\
		25\%  &	20\\
		50\%  &	20\\
		75\%  &	20\\
		max   &	54 \\
		\bottomrule
	\end{tabular}
\end{table}

\newpage
\section{Теоретические основы} 

\subsection{Задача многоклассовой классификации изображений}

Задача многоклассовой классификации изображений заключается в том, чтобы отнести каждое изображение из набора данных к одной из заранее определенных категорий или классов. Для решения задачи необходимо использовать разнообразный набор изображений, каждый из которых должен быть помечен (аннотирован) соответствующим классом.

Для многоклассовой классификации часто используют сверточные нейронные сети, такие как ResNet, MobileNet или EfficientNet. Для оценки качества модели обычно применяются следующие метрики: Accuracy, Precision, Recall и F1-score (подробнее см. в разделе \ref{classification_metrics}).

Для повышения производительности модели можно использовать различные методы, например:
\begin{itemize}
	\item тонкая настройка гиперпараметров — корректировка параметров обучения, таких как скорость обучения, размер батча и т.д.
	\item дополнительная аугментация данных — применение различных преобразований к изображениям, таких как повороты, сдвиги, масштабирование, для увеличения разнообразия обучающих данных.
	\item использование предобученных моделей — начинать обучение с модели, предварительно обученной на большом наборе данных, таком как ImageNet.
\end{itemize}

\subsection{Обзор классификаторов изображения}

В этом разделе будет дан обзор существующих классификаторов изображений, а также будет выбрана архитектура модели, которая будет использоваться в проекте, в том числе для использования ее в качестве кодировщика в задаче Image Captioning.
 
\subsubsection{ResNet}

ResNet (Residual Neural Network) — это семейство моделей нейронных сетей, разработанные для решения проблемы затухания градиента \cite{resnet}. Модели получили широкое признание и стали основой для многих современных архитектур благодаря своей способности эффективно тренировать очень глубокие нейронные сети.

Ключевой инновацией ResNet является использование остаточных блоков (англ., residual blocks), которые помогают бороться с проблемой затухания градиентов в очень глубоких сетях. Основная идея заключается в том, чтобы добавить прямые связи (англ., skip connections) через несколько слоев, что позволяет градиентам легче проходить через сеть.

Остаточный блок — это компонент архитектуры ResNet, который содержит «обходную связь идентичности», обходящую один или большее количество слоев. Остаточный блок состоит из двух или трех сверточных слоев с прямой связью, которая пропускает входы блока напрямую к его выходу. Это помогает сохранять информацию от предыдущих слоев и упрощает обучение. На рисунке \ref{fig:res-block} представлен пример остаточного блока.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=1.5]{res_block.png}
	\caption{Остаточный блок \cite{resnet}.}
	\label{fig:res-block}
\end{figure}

ResNet предлагает несколько версий моделей с различной глубиной: ResNet-18, ResNet-34, ResNet-50, ResNet-101, ResNet-152. Эти версии различаются количеством остаточных блоков и слоев, что позволяет выбрать модель, соответствующую конкретной задаче и доступным вычислительным ресурсам.

\subsubsection{MobileNet}

MobileNet — это семейство моделей нейронных сетей, специально разработанных для работы на мобильных и встраиваемых устройствах \cite{mobilenet}. Они оптимизированы для эффективности и производительности, обеспечивая высокую точность при низких вычислительных затратах. MobileNet широко используется в задачах компьютерного зрения, таких как классификация изображений, детекция объектов и сегментация.

Основной инновацией MobileNet является использование глубоких разделяемых сверточных слоев вместо стандартных сверточных слоев. Глубокие разделяемые сверточные слои состоят из двух отдельных операций: глубинного свертывания (англ., depthwise convolution) и точечного свертывания (англ., pointwise convolution). Глубинное свертывание применяется отдельно к каждому каналу входного изображения, а точечное свертывание используется для объединения выходов глубинного свертывания. MobileNet использует параметры разложения для управления шириной сети (англ., width multiplier) и разрешением входного изображения (англ., resolution multiplier).  Width multiplier уменьшает количество каналов в каждой сверточной операции, что снижает количество вычислений и параметров, а resolution multiplier уменьшает размер входного изображения, что дополнительно снижает вычислительные затраты. Благодаря глубинным разделяемым сверточным слоям и параметрам разложения, MobileNet достигает хорошего баланса между производительностью и вычислительными затратами. На рисунке \ref{fig:mobilenet} представлена архитектура MobileNet слоя.


\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.8]{mobilenet.png}
	\caption{Архитектура MobileNet слоя \cite{mobilenet}.}
	\label{fig:mobilenet}
\end{figure}

На данный момент существует несколько версий MobileNet, каждая из которых приносит свои улучшения и оптимизации.

MobileNetV2 — включает улучшения, такие как инвертированные остаточные блоки (англ., inverted residuals) и линейные узкие слои (англ., linear bottlenecks) \cite{mobilenetv2}. Эти улучшения помогают сохранять более полезные характеристики признаков и обеспечивают лучшую производительность при тех же вычислительных затратах. Разница между остаточным и инвертированным остаточным блоком представлена на рисунке \ref{fig:mobilenetv2}.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.4]{mobilenetv2.png}
	\caption{Разница между остаточным и инвертированным остаточным блоком \cite{mobilenetv2}.}
	\label{fig:mobilenetv2}
\end{figure}

MobileNetV3 — включает дополнительные улучшения, такие как блоки сжатия и возбуждения (англ., squeeze-and-excitation, SE) и расширенные функции активации \cite{mobilenetv3},  см. рисунок  \ref{fig:mobilenetv3}. Блоки SE позволяют сети лучше фиксировать канальные зависимости в данных, помогает повысить способность модели извлекать значимые функции из входных данных, что приводит к повышению производительности задач распознавания изображений. MobileNetV3 использует расширенные функции активации, такие как h-swish и h-sigmoid. Эти функции обеспечивают более плавные градиенты во время обучения, что может привести к более быстрой сходимости и повышению общей производительности. MobileNetV3 предоставляет две версии: MobileNetV3-Large и MobileNetV3-Small, предназначенные для различных требований производительности и эффективности.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.2]{mobilenet-v3-block.png}
	\caption{MobileNetV3 блок \cite{mobilenetv3}.}
	\label{fig:mobilenetv3}
\end{figure}


Однако, несмотря на свою эффективность и компактность, MobileNet в сравнении с более крупными и сложными моделями, такими как EfficientNet, может не достигать такой же высокой точности на некоторых задачах компьютерного зрения.

\subsubsection{EfficientNet}

EfficientNet — архитектура нейронной сети, которая основывается на идеи масштабирования моделей и балансирования между собой глубины и ширины (количества каналов) сети, а также разрешения изображений\cite{efficientnet}. Предлагается новый метод составного масштабирования (англ., compound scaling method), который равномерно изменяет глубину, ширину и разрешение с фиксированными пропорциями между ними. Метод составного масштабирования показан на рисунке \ref{fig:scaling_method}.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.3]{scaling_method.png}
	\caption{Различные методы масштабирования по сравнению со составным\cite{efficientnet}.}
	\label{fig:scaling_method}
\end{figure}

Архитектура EfficientNet состоит из следующих ключевых компонентов:
\begin{enumerate}[label=\arabic*.]
	\item MBConv (англ., Mobile Inverted Bottleneck Convolution) — основной строительный блок EfficientNet, унаследованный из архитектуры MobileNetV2. MBConv включает в себя следующие элементы:
	\begin{itemize}
		\item Pointwise Convolution (1x1) — уменьшает размерность каналов, улучшая вычислительную эффективность.
		\item Depthwise Convolution (3x3 или 5x5) — выполняет свертку по каждому каналу независимо, что значительно снижает количество параметров.
		\item Squeeze-and-Excitation Block — улучшает представление важных характеристик путем адаптивного перенастроя каналов.
	\end{itemize}
	\item Использование функции активации Swish, которая демонстрирует лучшие результаты в глубоких сетях благодаря своей непрерывности и плавности.
	\item Compound Scaling — ключевая концепция EfficientNet, включающая одновременное масштабирование трех аспектов модели:
	\begin{itemize}
		\item Глубина — увеличение количества слоев в сети.
		\item Ширина — увеличение количества каналов в каждом слое.
		\item Разрешение — увеличение разрешения входных изображений.
	\end{itemize}
	Подход compound scaling обеспечивает сбалансированное увеличение модели, что позволяет достигать высокой точности и производительности без чрезмерного увеличения вычислительных затрат, что делает EfficientNet особенно привлекательной для внедрения в мобильные устройства.
\end{enumerate}

Существует несколько версий EfficientNet, каждая из которых разработана для различных применений и требований к вычислительным ресурсам. Оригинальные модели используют простой метод compound scaling, который включает масштабирование глубины, ширины и разрешения изображений с помощью фиксированных коэффициентов. В то время как EfficientNetV2 улучшает этот метод, вводя динамическое масштабирование, которое позволяет более гибко адаптировать модель к различным задачам и условиям. Также EfficientNetV2 использует улучшенные блоки, такие как Fused-MBConv, которые объединяют традиционные MBConv и элементы из ResNet, что позволяет увеличить эффективность обучения и улучшить качество представления данных.

Оригинальные модели EfficientNet (B0 - B7):
\begin{itemize}
\item EfficientNet-B0 — базовая модель, на основе которой построены все остальные версии, использует минимальное количество параметров и вычислительных ресурсов. Архитектура сети представлена на рисунке \ref{fig:efficientnet-b0}
\item EfficientNet-B1 - B7 — модели, которые последовательно масштабируются с использованием compound scaling, увеличивая глубину, ширину и разрешение. Каждая последующая версия обладает большей вычислительной мощностью и точностью по сравнению с предыдущей.
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.3]{efficientnet-b0.png}
	\caption{Архитектура базовой сети EfficientNet-B0\cite{efficient-b0}.}
	\label{fig:efficientnet-b0}
\end{figure}

Модели EfficientNetV2 (S, M, L):
\begin{itemize}
\item EfficientNetV2-S — оптимизированная версия для мобильных устройств, характеризующаяся компактностью и высокой эффективностью. Подходит для приложений, где критичны вычислительные ресурсы и время отклика.
\item EfficientNetV2-M — средняя версия, предлагающая баланс между производительностью и вычислительными затратами. Часто используется в серверных и облачных средах.
\item EfficientNetV2-L — наиболее мощная версия, предназначенная для задач, требующих максимальной точности и производительности. Используется в высокопроизводительных системах и приложениях с большими объемами данных.
\end{itemize}

Благодаря продуманному подходу к масштабированию, все версии EfficientNet демонстрируют высокую точность на стандартных наборах данных, таких как ImageNet. Стоит отметить, что модели EfficientNetV2 значительно превосходят оригинальные модели EfficientNet. Так например, EfficientNetV2-M снижает параметры на 17 \%, а количество операций ввода-вывода — на 37 
\%, но при этом работает в 4.1 раза быстрее при обучении и в 3.1 раза быстрее при выводе, чем EfficientNet-B7. Также модели EfficientNetV2 значительно быстрее и обеспечивают лучшую точность и эффективность параметров, чем предыдущие модели ConvNet и Vision Transformers на ImageNet \cite{efficientnetv2}. Несмотря на высокую производительность, EfficientNetV2 не использует механизм внимания, как ViT, что может быть недостатком в некоторых случаях. 

\subsubsection{Vision Transformers}

Визуальные трансформеры (англ., Vision Transformers, ViTs) – класс моделей глубокого обучения, которые представляют собой архитектуру в области компьютерного зрения, адаптированную из трансформеров, широко используемых в обработке естественного языка \cite{vit}. Основная идея заключается в разделении изображения на небольшие патчи (части), которые затем обрабатываются как токены последовательности в модели трансформера. ViTs используют механизм самовнимания для анализа изображений, что позволяет моделям эффективно захватывать глобальные и локальные зависимости в данных. Vision Transformers достигли выдающихся результатов в задачах классификации изображений.

Архитектура Vision Transformers состоит из следующих этапов (см. рисунок \ref{fig:vit}):
\begin{enumerate}[label=\arabic*.]
	\item Разделение на патчи. Изображение делится на небольшие патчи фиксированного размера (например, 16x16 пикселей), которые затем выравниваются в одномерные векторы. Каждый патч рассматривается как токен в последовательности.
	\item Линейное преобразование патчей. Каждому патчу сопоставляется эмбеддинг фиксированной размерности с помощью линейного слоя. Этот шаг аналогичен созданию эмбеддингов для слов в задачах NLP.
	\item Добавление позиционных эмбеддингов. Поскольку трансформеры изначально не содержат информации о позиции токенов, то к эмбеддингам патчей добавляются позициионные эмбеддинги, которые кодируют пространственное положение каждого патча в исходном изображении.
	\item Последовательность патчей передается через многослойную трансформерную модель, состоящую из чередующихся слоев самовнимания (self-attention) и полносвязных слоев (feed-forward), c целью учесть взаимосвязи между всеми патчами одновременно, эффективно захватывая глобальные и локальные зависимости в изображении.
	\item К началу последовательности патчей добавляется специальный классификационный токен CLS, который предназначен для агрегирования информации от всех патчей и используется для финальной классификации. Выходной эмбеддинг CLS токена передается через несколько полносвязных слоев с функцией активации (например, ReLU), завершающихся слоем Softmax для получения вероятностей классов. Финальная классификационная голова преобразует выходной эмбеддинг в предсказание класса для всего изображения.
\end{enumerate}

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.3]{vit.png}
	\caption{Архитектура Vision Transformers\cite{vit}.}
	\label{fig:vit}
\end{figure}

Архитектура Vision Transformers достигла высоких показателей производительности в задаче классификации изображений на датасете ImageNet после предварительного обучения на JFT-300M \cite{vit}. Однако важно отметить, что эффективность моделей резко снижается при использовании небольших объемов данных для предварительного обучения. Более крупные модели чаще всего показывают лучшие результаты на больших наборах данных. Это проблема, вероятно, связана с тем, что трансформерные сети не имеют предварительных предположений о порядке данных, что может привести к их недостаточной адаптации к конкретным требованиям задачи или к обучающему набору данных.



\subsection{Используемые метрики в задаче классификации}\label{classification_metrics}
В задаче классификации для оценки качества моделей машинного обучения используются специальные показатели — метрики.

Для описания метрик используется матрица ошибок классификаций (англ. confusion matrix). Пусть есть два класса и метод, предсказывающий принадлежность каждого объекта одному из классов. В таблице \ref{confusion_matr} представлена матрица ошибок классификации.

\begin{table}[h]
	\centering
	\begin{tabular}{ | l | l | l | }
		\hline
		& $y = 1$ & $y = 0$ \\ \hline
		$\hat{y} = 1$ & True Positive (TP) & False Positive (FP) \\ \hline
		$\hat{y} = 0$ & True Negative (TN) & False Negative (FN) \\ \hline
	\end{tabular}
	\caption{Матрица ошибок классификации.
		$y$ — истинный класс, $\hat{y}$ — результат модели.}
	\label{confusion_matr}
\end{table}

Простейшей метрикой является accuracy — доля правильных ответов:

\begin{equation}
	\label{acc}
	accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}

Стоит отметить, что эта метрика может быть применима только на сбалансированном датасете. 


Для оценки качества работы алгоритма на каждом из классов по отдельности вводятся метрики точность (англ. precision)  и полнота (англ. recall): 

\begin{equation}
	\label{precision}
	precision = \frac{TP}{TP + FP}
\end{equation}

\begin{equation}
	\label{recall}
	recall = \frac{TP}{TP + FN}
\end{equation}

Precision — доля объектов, которые классификатор определил как положительные и при этом они действительно являются положительными, а recall — метрика, которая показывает, какую долю положительных объектов из всех объектов положительного класса обнаружила модель. Введение precision не позволяет определять все объекты в один класс, так как в этом случае получается рост FP. Recall показывает способность метода вообще обнаруживать данный класс, а precision — способность отличать этот класс от других. В отличие от accuracy, recall и precision не зависят, от соотношения классов и поэтому могут быть применимы на несбалансированном датасете.

Также существует несколько способов объединить recall и precision в объединенный критерий оценки. Например, F-мера (в общем случае $\ F_\beta$) — среднее гармоническое recall и precision:

\begin{equation}
	\label{acc3}
	\large \ F_\beta = (1 + \beta^2) \cdot \frac{precision \cdot recall}{(\beta^2 \cdot precision) + recall}
\end{equation}

$\beta$ в данном случае определяет вес точности в метрике. 

F-мера достигает максимума при точности и полноте, равными 1, и близка к 0, если один из аргументов близок к 0.

\subsection{Задача создания подписей к изображениям}

Задача создания подписей к изображениям (от англ. image captioning) предполагает использование методов глубокого обучения для генерации текстовых описаний на основе визуального содержимого изображений. Для решения этой задачи используется архитектура кодера-декодера (от англ. encoder-decoder). Основные подходы для ее реализации:
\begin{enumerate}[label=\arabic*.]
	\item Использование комбинации сверточных нейронных сетей для обработки изображения и рекуррентных нейронных сетей для генерации подписи. 
	\item Использование трансформеров. 
\end{enumerate}

Архитектура с использованием комбинации CNN и RNN представлена на рисунке. В качестве кодировщика используется CNN, такие как ResNet, MobileNet или EfficientNet. Эти модели предварительно обучены на больших наборах данных, таких как ImageNet, для извлечения визуальных признаков. Кодировщик отвечает за преобразование изображения в компактное представление (вектор признаков), которое сохраняет важную информацию об изображении. В качестве вектора признаков изображения может использоваться выходной слой CNN, но чаще всего это слой перед последним полносвязанным. Декодировщик принимает вектор признаков изображения и генерирует последовательность слов, которая описывает изображение. Декодеры, как правило, основаны на рекуррентных нейронных сетях (RNN), такие как LSTM (Long Short-Term Memory) или GRU (Gated Recurrent Unit) для генерации последовательности слов. Одна из основных проблем такого подхода — это то, что RNN имеет фиксированную длину контекста и обрабатывает информацию последовательно. Это означает, что RNN видит только небольшой контекст, поэтому при генерации слов часто забывает старые результаты своей генерации. Так же такой подход не позволяет полностью учесть контекст изображения на каждом этапе генерации. В данном случае выделенные признаки изображения с помощью CNN лишь единожды подаются на вход LSTM блока, так что со временем генерация полностью теряет память о исходном изображении и начинает "додумывать самостоятельно". Для решения этих проблем применяется механизм внимания. В случае image captioning, механизм внимания позволяет сети "обращаться" к различным частям изображения на каждом шаге генерации текста. Таким образом контекст самого изображения не теряется со временем генераций, и механизм внимания позволяет сети сфокусироваться на разных частях изображения с разной степенью "важности" на каждом шаге генерации, что значительно увеличивает качество финального описания. На рисунке \ref{fig:image-captioning-decoder} представлена архитектура декодировщика.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.4]{image-captioning-arch.png}
	\caption{Архитектура задачи Image Captioning.}
	\label{fig:image-captioning-arch}
\end{figure}

Преимущества реализации:
\begin{itemize}
	\item высокая точность и производительность; 
	\item способность обрабатывать большие объемы данных и извлекать сложные зависимости.
\end{itemize}

К недостатком данной архитектуры можно отнести требование к большим вычислительным ресурсам для обучения и инференса модели.

Архитектура  с использованием трансформеров представлена на рисунке. В качестве кодера используется Vision Transformers (ViTs), который применяет механизмы самовнимания к патчам изображения для извлечения признаков. В качестве декодера используются модели GPT, которые также используют механизмы самовнимания для моделирования долгосрочных зависимостей в тексте, что позволяет генерировать более связные и правильные описания. Ключевым моментом является правильная подача признаков изображения, извлеченных из ViTs, в соответствующие слои самовнимания GPT, то есть преобразование этих признаков в формат ключей (keys), значений (values) и запросов (queries).

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.4]{image-captioning-arch.png}
	\caption{Архитектура задачи Image Captioning.}
	\label{fig:image-captioning-arch}
\end{figure}

Преимущества реализации:
\begin{itemize}
	\item высокая точность и производительность; 
	\item способность обрабатывать большие объемы данных и извлекать сложные зависимости.
\end{itemize}

К недостатком данной архитектуры можно отнести требование к большим вычислительным ресурсам для обучения и инференса модели.

Стоит отметить, что совместить способы решения задачи нельзя, из-за фундаментальных различий в их архитектурных подходах и методах обработки данных. CNN и RNN работают на основе последовательной обработки данных, в то время как ViTs и GPT используют механизмы самовнимания, которые позволяют параллельно обрабатывать данные. Комбинация подходов может потребовать значительных изменений в архитектурах, что вряд ли приведет к улучшению результатов. Поэтому выбор архитектуры (CNN + RNN или ViT + GPT) зависит от конкретных требований проекта и условий, в которых будет использоваться модель. В некоторых случаях может быть полезным попробовать обе архитектуры и выбрать ту, которая лучше соответствует задачам и ресурсам. Для оценки качества генерации используются метрики, такие как BLEU, WER, METEOR и CIDEr.

\subsection{Обзор моделей для генерации текста}

В данном разделе рассматриваются ключевые модели генерации текста, их архитектурные особенности, а также преимущества и недостатки.

\subsubsection{Рекуррентные нейронные сети}

Рекуррентные нейронные сети (Recurrent Neural Networks, RNN) — это класс нейронных сетей, специально разработанных для обработки последовательных данных. RNN широко применяются в задачах, где порядок и зависимость данных во времени играют важную роль, например, в таких как обработка текста и генерация последовательностей.

RNN способны учитывать временные зависимости в данных, обрабатывая последовательности входных сигналов. Это достигается благодаря наличию скрытых состояний (hidden states), которые обновляются на каждом шаге последовательности и хранят информацию о предыдущих шагах. В отличие от обычных нейронных сетей, RNN имеют петли обратной связи, позволяющие информации циркулировать внутри сети. Это позволяет RNN "помнить" предыдущие шаги и использовать эту информацию для текущих вычислений (см. рисунок \ref{fig:rnn_arch}).

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.3]{rnn_arch.png}
	\caption{Архитектура RNN.}
	\label{fig:rnn_arch}
\end{figure}

На каждом шаге \( t \) входной вектор \( x_t \) и предыдущее скрытое состояние \( h_{t-1} \) используются для вычисления текущего скрытого состояния \( h_t \):
\begin{equation}
	\label{rnn_hidden_layer}
	h_t = \tanh(W_h h_{t-1} + W_x x_t + b_h)
\end{equation}
где \( W_h \) и \( W_x \) — веса, \( b_h \) — смещение, и \( \tanh \) — активационная функция.

При обучении очень длинных последовательностей RNN могут столкнуться с проблемой затухания или взрыва градиентов. Это приводит к тому, что веса либо становятся очень маленькими, либо слишком большими, что затрудняет обучение. 

Для решения проблем затухания и взрыва градиентов были предложены более сложные архитектуры, такие как Long Short-Term Memory (LSTM) и Gated Recurrent Unit (GRU).

LSTM — это разновидность RNN, специально разработанная для борьбы с проблемой затухания градиентов. LSTM используют специальные ячейки памяти и механизмы управления потоком информации (забывающие и обновляющие ворота), что позволяет им эффективно хранить и обрабатывать данные с долгосрочными зависимостями, что было недостижимо для традиционных RNN.


Ячейка LSTM состоит из трех основных компонентов:
\begin{enumerate}
	\item Ворота забывания (англ., Forget Gate), которые используются для управления продолжительностью памяти в ячейке, решая, какую информацию следует забыть, а какую сохранить.
	\item Ворота ввода (англ., Input Gate), которые определяют, какая часть новой информации должна быть сохранена в долгосрочной памяти ячейки LSTM. Они не только фильтруют входные данные, но и решают, какая информация достаточно важна для сохранения.
	\item Ворота вывода (англ., Output Gate), которые определяют, какая информация из текущего состояния ячейки будет передана в выходной сигнал сети.
\end{enumerate}

Архитектура ячейки LSTM представлена на рисунке

GRU — это упрощенная версия LSTM, которая объединяет забывающие и обновляющие ворота в одно целое, что делает архитектуру менее вычислительно затратной и более простой для реализации. В GRU нет отдельной ячейки памяти, как в LSTM. Вместо этого, она обновляет скрытое состояние напрямую. Ворота обновления помогают модели решить, какая часть предыдущего скрытого состояния должна быть сохранена. Это делается путем комбинирования прошлого состояния и новой информации.

GRU использует два основных компонента:

- Ворота обновления (англ., Update Gate):
\[ z_t = \sigma(W_z \cdot [h_{t-1}, x_t] + b_z) \]
- Ворота сброса (англ., Reset Gate):
\[ r_t = \sigma(W_r \cdot [h_{t-1}, x_t] + b_r) \]
\[ \tilde{h}_t = \tanh(W_h \cdot [r_t \cdot h_{t-1}, x_t] + b_h) \]
\[ h_t = (1 - z_t) \cdot h_{t-1} + z_t \cdot \tilde{h}_t \]

Выбор между LSTM и GRU зависит от конкретных требований задачи. Если скорость обучения является приоритетом и доступные вычислительные ресурсы ограничены, то использование GRU может быть предпочтительнее благодаря своей более простой структуре и меньшему количеству параметров по сравнению с LSTM. Также использование GRU может быть достаточным для более простых или меньших наборов данных, так как она способна эффективно обучаться на таких данных без потери производительности. Однако если задача требует более детального управления информацией и долгосрочной памяти (например, в сложных задачах обработки естественного языка с длинными зависимостями), то LSTM может быть более подходящим выбором благодаря своей дополнительной сложности и дополнительному контролю над информацией.

\subsubsection{Модели генеративного предварительно обученного трансформера}

Модели генеративного предварительно обученного трансформера, (англ. Generative Pre-trained Transformer, GPT) — это семейство языковых моделей на основе глубокого обучения, разработанные командой OpenAI, которые используют архитектуру трансформера (см. рисунок \ref{fig:transformers_arch}) для генерации текста, учитывая контекст и структуру предложений. Модели GPT являются мощными инструментами для генерации текста и решения разнообразных задач в области естественного языка. Их успешное функционирование основано на комбинации трансформерной архитектуры, предварительного обучения на больших объемах текстовых данных и тщательного дообучения на конкретной задаче.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.7]{transformer.png}
	\caption{Архитектура трансформера \cite{transformers}.}
	\label{fig:transformers_arch}
\end{figure}

Архитектура GPT имеет два основных сегмента: кодировщик, который в основном работает с входной последовательностью, и декодер, который работает с целевой последовательностью во время обучения и предсказывает следующий элемент.  Кодер определяет, какие части ввода следует выделить. Затем он вычисляет матрицу встраивания (встраивание в NLP позволяет словам с похожим значением иметь одинаковое представление) и преобразует ее в серию векторов внимания. Модели  GPT используют многоголовое внимание (англ., multi-head attention), которое создает векторы внимания, позволяя модели одновременно фокусироваться на разных частях последовательности. Это позволяет захватывать различные аспекты контекста языка. Созданные вектора внимания проходят через слой нормализации и затем передаются в полносвязный слой. Нормализация помогает стабилизировать и ускорить процесс обучения. Перед передачей в декодер снова выполняется нормализация. Во время обучения кодер работает непосредственно с целевой выходной последовательностью.  Декодер вычисляет отдельные векторы встраивания для каждого слова предложения. Поскольку трансформеры не имеют встроенной последовательности обработки данных, то дополнительно применяется позиционный энкодер с синусоидальными и косинусоидальными функциями. Кроме того, модель GPT обучается предсказывать следующий токен в последовательности. Для этого используется механизм маскированного внимания (англ., masked attention), который позволяет модели видеть только предшествующие токены. Во время генерации текста модель принимает на вход начальный токен или последовательность токенов и последовательно предсказывает следующие токены, генерируя текст по одному слову за раз. Процесс генерации продолжается до достижения определенного критерия остановки, например, такого как достижение максимальной длины текста или специального токена окончания.

Прежде чем приступить к выполнению конкретной задачи, модели GPT проходят через фазу предварительного обучения на больших корпусах текстовых данных. Во время предварительного обучения модель учится "понимать" структуру и смысл текста, а также создавать внутреннее представление о языке. После предварительного обучения модель может быть дообучена или донастроена на конкретной задаче, что улучшает ее производительность и качество результатов.


На данный момент существует несколько версий GPT, каждая из которых приносит свои улучшения и оптимизации:
\begin{enumerate}[label=\arabic*.]
	\item GPT-1 — первая модель из семейства GPT, которая содержит 117 миллионов параметров. Сложность обучения GPT-1 варьируется в зависимости от доступных вычислительных ресурсов и объема данных для обучения, но в то же время остается доступной для исследователей и специалистов благодаря наличию предобученных моделей. 
	\item GPT-2 содержит 1.5 миллиарда параметров. Обучение GPT-2 требует больших объемов данных и вычислительных ресурсов, что делает его более сложным в обучении, чем GPT-1. Для многих исследовательских групп доступ к достаточным ресурсам может быть препятствием для обучения GPT-2, хотя предобученные модели могут быть доступны для использования.
	\item GPT-3 содержит 175 миллиардов параметров. Обучение GPT-3 требует огромных вычислительных ресурсов и больших объемов данных, что делает его крайне сложным в обучении. Для большинства исследовательских групп доступ к таким ресурсам может быть недостижимым. Кроме того, обучение GPT-3 может требовать значительных финансовых затрат на инфраструктуру и вычислительные ресурсы.
	\item GPT-4 — мультимодальная большая языковая модель, которая способна обрабатывать запросы в виде картинок и текста, а затем выдавать текстовые ответы. В качестве трансформера GPT-4 была предварительно обучена прогнозировать следующий токен (используя как общедоступные данные, так и «данные, лицензированные сторонними поставщиками»), а затем была доработана с помощью обучения с подкреплением на основе отзывов людей. В техническом отчете GPT-4 явно воздерживаются от указания размера модели, ссылаясь на «конкурентную среду и последствия для безопасности крупномасштабных моделей», но согласно оценки разных источников GPT-4 имеет около 1.76 триллиона параметров.
\end{enumerate}

Для обучения любой модели GPT требуется тщательное планирование и анализ с целью определения оптимальных методов и ресурсов. Это включает выбор подходящего объема данных для обучения, оптимизацию гиперпараметров модели, выбор архитектуры и распределение вычислительных ресурсов. Обучение моделей GPT может быть довольно сложным, но при правильном планировании и наличии необходимых ресурсов эти сложности возможно преодолеть.

\subsection{Используемые метрики в задаче создания подписей к изображениям}

\subsection{Вывод}

Этапы развития работы:
0) Классификатор на основе efficient net на ~1.5k классов
0.0) Если из коробки качество и скорость классификации на все классы сразу страдают (а они скорее всего будут), то внедрить многоуровневую иерархию моделей попроще.

1) RNN-based архитектура, где энкодер представлен efficient net, а декодер - соответствующей частью LSTM/GRU.
Можно улучшать комплексность модели: 
1.0) количество параллельных LSTM, чей результат в итоге аггрегируется
1.1) многоуровневая LSTM, где скрытые состояния k-ого уровня передаются входом в k+1ый
1.2) добавить механизм внимания (attention) к модели

2) Трансформеры, где мы будем бить картинку на последовательность частей и получать соответствующие эмбеддинги для этих самых частей. Затем информацию из энкодера будем подмешивать через attention в декодере, который может быть представлен LLAMA/GPT-2

\newpage
\section{Проектирование архитектуры программного продукта (в процессе)}
В 2022 году граждане Российской Федераций столкнулись с трудностями работы с магазинами приложений для смарт-устройств. Так, например, с 24 февраля из российского раздела App Store были удалены почти 7000 мобильных приложений \cite{russia_app}. Поэтому при построении архитектуры приложения был выбран подход к созданию клиент-серверного приложения, которое будет работать практически на любом устройстве (стационарный компьютер, ноутбук, планшет или смартфон). Одним из способов реализации такого подхода является написание telegram  бота. В настоящее время это одно из трендовых направлений в IT сфере. В 2024 году Telegram посещают 900 миллионов человек в месяц. По количеству аудитории он входит в пятерку самых популярных мессенджеров в мире. Выбор в пользу написания телеграм-бота вместо веб-приложения может быть обусловлен рядом факторов, включая удобство использования, скорость разработки, доступность, безопасность, а также гибкость и масштабированность для обработки большого количества пользователей.

За логику, работоспособность и правильное функционирование бота 
отвечает серверная часть (англ. backend), которая скрыта от пользователя. Серверная часть включает в себя:
\begin{itemize}
	\item модуль для обработки запросов от пользователя;
	\item модуль для взаимодействия с обученной моделями классификации для определения категории товара и генерации его описания.
\end{itemize}

В контексте работы с моделями машинного обучения и их применения в системах автономного управления, вынос предсказаний моделей в очередь сообщений может быть полезно для оптимизации работы и повышения устойчивости системы.

Для проектирования, разработки и обучения нейронных сетей использовался следующий стек технологий:
\begin{itemize}
	\item Язык программирования Python — язык общего назначения, с помощью которого можно решать сложные задачи машинного обучения и быстро создавать прототипы для последующей их отладки. Язык гибкий и мультиплатформенный, имеет обширный набор библиотек для искусственного интеллекта. Python удобно использовать для обработки и подготовки обучающих данных.
	\item Pytorch — библиотека глубокого обучения с открытым исходным кодом, написанная на языке Python и созданная на базе Torch. Используется для решения различных задач машинного обучения: компьютерное зрение, NLP, создания и обучения нейронных сетей \cite{pytorch}.
\end{itemize}

Вычисления происходили с использованием аппаратных ускорений на GPU Nvidia Tesla V100 и A100.

Для реализация серверной части был выбран Flask – это небольшой и легкий веб-фреймворк, написанный на языке Python, предлагающий полезные инструменты и функции для облегчения процесса создания веб-приложений с использованием Python \cite{flask}.

Docker — инструмент для создания и запуска контейнеров.

Kubernetes нужен, когда у вас много контейнеров и узлов, которыми нужно управлять. Также Kubernetes подходит, если вам нужна распределенная отказоустойчивая система.


На рисунке \ref{web_arch} представлена структура приложения.

\newpage
\section{Направление дальнейшего развития}

\newpage 
\printbibliography[heading=bibintoc]

\newpage
\appendix

\section{Приложение 1}
\label{appendix:amount_of_categor2}
\textbf{\large{Распределение данных по категориям второй вложенности.}}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Автотовары.png}
	\caption{Распределение данных в категории «Автотовары».}
	\label{fig:amount_of_category_Автотовары}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Аксессуары.png}
	\caption{Распределение данных в категории «Аксессуары».}
	\label{fig:amount_of_category_Аксессуары}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Бытовая&техника.png}
	\caption{Распределение данных в категории «Бытовая\&техника».}
	\label{fig:amount_of_category_Бытовая&техника}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Детям.png}
	\caption{Распределение данных в категории «Детям».}
	\label{fig:amount_of_category_Детям}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Для&ремонта.png}
	\caption{Распределение данных в категории «Для\&ремонта».}
	\label{fig:amount_of_category_Для&ремонта}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Дом.png}
	\caption{Распределение данных в категории «Дом».}
	\label{fig:amount_of_category_Автотовары}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Женщинам.png}
	\caption{Распределение данных в категории «Женщинам».}
	\label{fig:amount_of_category_Женщинам}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Здоровье.png}
	\caption{Распределение данных в категории «Здоровье».}
	\label{fig:amount_of_category_Здоровье}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Зоотовары.png}
	\caption{Распределение данных в категории «Зоотовары».}
	\label{fig:amount_of_category_Зоотовары}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Игрушки.png}
	\caption{Распределение данных в категории «Игрушки».}
	\label{fig:amount_of_category_Игрушки}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Канцтовары.png}
	\caption{Распределение данных в категории «Канцтовары».}
	\label{fig:amount_of_category_Канцтовары}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Книги.png}
	\caption{Распределение данных в категории «Книги».}
	\label{fig:amount_of_category_Книги}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Красота.png}
	\caption{Распределение данных в категории «Красота».}
	\label{fig:amount_of_category_Красота}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Мебель.png}
	\caption{Распределение данных в категории «Мебель».}
	\label{fig:amount_of_category_Мебель}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Мужчинам.png}
	\caption{Распределение данных в категории «Мужчинам».}
	\label{fig:amount_of_category_Мужчинам}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Обувь.png}
	\caption{Распределение данных в категории «Обувь».}
	\label{fig:amount_of_category_Обувь}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Продукты.png}
	\caption{Распределение данных в категории «Продукты».}
	\label{fig:amount_of_category_Продукты}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Сад&и&дача.png}
	\caption{Распределение данных в категории «Сад\&и\&дача».}
	\label{fig:amount_of_category_Сад&и&дача}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Товары&для&взрослых.png}
	\caption{Распределение данных в категории «Товары\&для\&взрослых».}
	\label{fig:amount_of_category_Товары&для&взрослых}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Электроника.png}
	\caption{Распределение данных в категории «Электроника».}
	\label{fig:amount_of_category_Электроника}
\end{figure}

\begin{figure}[hbtp]
	\centering
	\includegraphics[scale=0.8]{приложения/amount_of_category_Ювелирные&изделия.png}
	\caption{Распределение данных в категории «Ювелирные\&изделия».}
	\label{fig:amount_of_category_Ювелирные&изделия}
\end{figure}

\end{document}
