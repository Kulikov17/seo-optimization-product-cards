\newpage 
\printbibliography[heading=bibintoc] 

\begin{thebibliography}{0}
	\bibitem{ai}
	Искусственный интеллект [Электронный ресурс]. — Режим доступа https://www.ibm.com/topics/artificial-intelligence, свободный — (30.05.2024).
	
	\bibitem{ml}
	Машинное обучение [Электронный ресурс]. — Режим доступа: https://www.ibm.com/topics/machine-learning, свободный — (30.05.2024).
	
	\bibitem{cv}
	Компьютерное зрение [Электронный ресурс]. — Режим доступа: https://www.ibm.com/topics/computer-vision, свободный — (30.05.2024). 
	
	\bibitem{nlp}
	Словарь IT терминов [Электронный ресурс]. — Режим доступа: https://blog.skillfactory.ru/glossary/nlp/, свободный — (30.05.2024). 
	
	\bibitem{neural}
	Нейронная сеть [Электронный ресурс]. — Режим доступа: https://www.ibm.com/topics/neural-networks, свободный — (30.05.2024). 
	
	\bibitem{tinkoff-research}
	Исследования Tinkoff Ecommerce. Итоги года на маркетплейсах: в 2023 году [Электронный ресурс]. — Режим доступа: https://www.tinkoff.ru/about/news/29012024-marketplaces-year-results-number-of-purchases-increased-by-63-percent-in-2023/, свободный — (30.05.2024).
	
	\bibitem{turbotextpro}
	Сервис TurboText.Pro [Электронный ресурс]. — Режим доступа: https://turbotext.pro/, свободный — (30.05.2024).
	
	\bibitem{gerwin}
	Сервис Gerwin [Электронный ресурс]. — Режим доступа: https://app.gerwin.io/, свободный — (30.05.2024).
	
	\bibitem{copymonkey}
	Сервис CopyMonkey [Электронный ресурс]. — Режим доступа: https://www.copymonkey.app/, свободный — (30.05.2024).
	
	\bibitem{fashion_mnist}
	Датасет Fashion-MNIST [Электронный ресурс]. — Режим доступа: https://github.com/zalandoresearch/fashion-mnist, cвободный — (29.05.2024).
	
	\bibitem{victoria_secret_data}
	Датасет Innerwear Data from Victoria's Secret and Others [Электронный ресурс]. — Режим доступа: https://www.kaggle.com/datasets/PromptCloudHQ/innerwear-data-from-victorias-secret-and-others, cвободный — (29.05.2024).
	
	\bibitem{eсommerce_item_data}
	Датасет eCommerce Item Data [Электронный ресурс]. — Режим доступа: https://www.kaggle.com/datasets/cclark/product-item-data, cвободный — (29.05.2024).
	
	\bibitem{amazon_data} 
	Датасет Fashion Products on Amazon [Электронный ресурс]. — Режим доступа: https://data.world/promptcloud/fashion-products-on-amazon-com, cвободный — (29.05.2024).
	
	\bibitem{vit}
	Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer,
	Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale, 2021.
	
	\bibitem{efficientnetv2}
	Mingxing Tan, Quoc V. Le. EfficientNetV2: Smaller Models and Faster Training, 2021.
	
	\bibitem{efficient-b0}
	EfficientNet: повышение точности и эффективности с помощью AutoML и масштабирования моделей [Электронный ресурс]. — Режим доступа https://torontoai.org/2019/05/28/efficientnet-improving-accuracy-and-efficiency-through-automl-and-model-scaling/, свободный — (29.05.2024).
	
	\bibitem{resnet}
	Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. Deep Residual Learning for Image Recognition, 2015.
	
	\bibitem{mobilenet}
	Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, 2017.
	
	\bibitem{mobilenetv2}
	Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNetV2: Inverted Residuals and Linear Bottlenecks, 2019.
	
	\bibitem{mobilenetv3}
	Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan,
	Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, Hartwig Adam. Searching for MobileNetV3, 2019.
	
	\bibitem{efficientnet}
	Mingxing Tan, Quoc V. Le. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, 2020.
	
	\bibitem{cnn-rnn-image-captioning}
	Реализация архитектуры Image Captioning с использованием CNN и RNN [Электронный ресурс]. — Режим доступа: https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning, cвободный — (29.05.2024).
	
	\bibitem{arch-cnn-rnn-image-captioning}
	Архитектуры Image Captioning с использованием CNN и RNN [Электронный ресурс]. — Режим доступа: https://towardsdatascience.com/automatic-image-captioning-with-cnn-rnn-aae3cd442d83,cвободный — (29.05.2024).
	
	\bibitem{cnn-rnn-image-captioning-google}
	Create image captioning models: Overview [Электронный ресурс]. — Режим доступа: https://www.youtube.com/watch?v=LWIZj\_RJYjM, cвободный — (29.05.2024).
	
	\bibitem{vit-gpt2-image-captioning}
	Реализация архитектуры Image Captioning с использованием трансформеров [Электронный ресурс]. — Режим доступа: https://huggingface.co/nlpconnect/vit-gpt2-image-captioning, cвободный — (29.05.2024).
	
	\bibitem{transformers}
	Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. Attention Is All You Need, 2017.
	
	\bibitem{attention}
	Dzmitry Bahdanau, KyungHyun Cho Yoshua Bengio. Neural Machine Translation by jointly learning to align and translate, 2014.
	
	\bibitem{gpt-1}
	Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever. Improving Language Understanding by Generative Pre-Training, 2018.
	
	\bibitem{gpt-2}
	Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever. Language Models are Unsupervised Multitask Learners, 2019.
	
	\bibitem{gpt-3}
	Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei. Language Models are Few-Shot Learners, 2020.
	
	\bibitem{gpt-4}
	OpenAI Team. GPT-4 Technical Report, 2024.
	
	\bibitem{gpt-4-params} GPT-4 Parameters: The Future of Natural Language Processing. [Электронный ресурс] — Режим доступа: https://medium.com/@mlubbad/gpt-4-parameters-the-future-of-natural-language-processing-7f0f099070f8, свободный — (дата обращения: 29.05.24).
	
	
	\bibitem{pytorch} Официальный сайт Pytorch, документация. [Электронный ресурс] — Режим доступа: https://pytorch.org/, свободный — (дата обращения: 24.05.22).
	
\end{thebibliography}
