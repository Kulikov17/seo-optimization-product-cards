\newpage 
\printbibliography[heading=bibintoc] 

\begin{thebibliography}{0}
	\bibitem{chirkova18}\hypertarget{chirkova18}{}
	\href{https://arxiv.org/abs/1810.10927}
	{Nadezhda Chirkova, Ekaterina Lobacheva, Dmitry Vetrov. Bayesian Compression for Natural Language Processing. In EMNLP 2018.}
	
	\bibitem{vit}
	Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer,
	Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale, 2021.
	
	\bibitem{efficientnetv2}
	Mingxing Tan, Quoc V. Le. EfficientNetV2: Smaller Models and Faster Training, 2021.
	
	\bibitem{transformers}
	Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. Attention Is All You Need, 2017.
	
	\bibitem{ai}
	Искусственный интеллект [Электронный ресурс]. — Режим доступа https://www.ibm.com/ru-ru/cloud/learn/what-is-artificial-intelligence, свободный — (10.11.2021).
	
	\bibitem{deepfake}
	Thanh Thi Nguyen, Quoc Viet Hung Nguyen, Cuong M. Nguyen, Dung Nguyen, Duc Thanh Nguyen, Saeid Nahavandi. Deep Learning for Deepfakes Creation and
	Detection: A Survey, 2021.
	
	\bibitem{deepfake_galkin} Владислава Галкина оживили ради продолжения «Диверсанта». [Электронный ресурс]. — Режим доступа: https://www.kp.ru/daily/27385/4580073/, cвободный — (30.04.2022).
	
	\bibitem{pytorch} Официальный сайт Pytorch, документация. [Электронный ресурс] — Режим доступа: https://pytorch.org/, свободный — (дата обращения: 24.05.22).
	
\end{thebibliography}
